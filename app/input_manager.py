### Einlesen CSV

import os
import pandas as pd
import datetime as dt
import re
import pdfplumber

def find_csv_and_pdf_files(path: str) -> tuple[list[str], list[str]]:
    """
    Sucht nach allen CSV- und PDF-Dateien in einem Verzeichnis und gibt deren Pfade zur√ºck.
    Gibt zus√§tzlich Feedback zur Anzahl der gefundenen Dateien.
    """
    if not os.path.isdir(path):
        raise NotADirectoryError(f"‚ùå Der Pfad ist kein g√ºltiges Verzeichnis: {path}")

    files = os.listdir(path)
    
    if not files:
        raise FileNotFoundError("‚ùå Keine Dateien im angegebenen Verzeichnis gefunden.")

    csv_files = [os.path.join(path, f) for f in files if f.lower().endswith(".csv")]
    pdf_files = [os.path.join(path, f) for f in files if f.lower().endswith(".pdf")]

    print(f"üìÑ Gefundene CSV-Dateien: {len(csv_files)}")
    print(f"üìÑ Gefundene PDF-Dateien: {len(pdf_files)}")

    if not pdf_files:
        raise FileNotFoundError("‚ùå Keine PDF-Datei gefunden. Bitte stelle sicher, dass mindestens eine PDF im Ordner liegt.")

    return csv_files, pdf_files

def detect_separator(filepath: str) -> str:
    """
    Erkennt automatisch das Trennzeichen in der ersten Zeile der Datei.
    Unterst√ºtzt ',', ';' und Tabulator ('\\t').
    """
    with open(filepath, encoding="utf-8") as f:
        first_line = f.readline()

    # Z√§hle Vorkommen m√∂glicher Trenner
    candidates = {",": first_line.count(","), ";": first_line.count(";"), "\t": first_line.count("\t")}

    # W√§hle den Trenner mit den meisten Vorkommen
    best = max(candidates, key=candidates.get)

    # Warnung, falls alles gleich 0 ist (z.‚ÄØB. eine leere oder ungew√∂hnliche Datei)
    if candidates[best] == 0:
        print("‚ö†Ô∏è Kein g√§ngiges Trennzeichen erkannt, Standardwert ',' wird verwendet.")
        return ","

    return best

def parse_date_string(date_str: str) -> pd.Timestamp | None:
    """Konvertiert Strings wie '2010', 'heute', 'today' in ein Datum, sonst None."""
    date_str = date_str.strip().lower()
    today = pd.Timestamp.today().normalize()

    if date_str in {"heute", "today"}:
        return today

    try:
        return pd.to_datetime(date_str, errors="raise", dayfirst=True)
    except Exception:
        return None
    
def parse_period_string(entry: str) -> tuple[pd.Timestamp, pd.Timestamp] | None:
    """
    Erkennt entweder:
    - Einzelzeitpunkt wie '2010', 'heute' ‚Üí Start = End
    - Zeitraum wie '2010 - 2015' ‚Üí Start, End
    Gibt: (start, end) oder None
    """
    entry = entry.strip()

    # Trenne Bereich
    split_match = re.split(r"\s*[-‚Äìbis]+\s*", entry, maxsplit=1)
    if len(split_match) == 1:
        date = parse_date_string(split_match[0])
        return (date, date) if date else None
    elif len(split_match) == 2:
        start = parse_date_string(split_match[0])
        end = parse_date_string(split_match[1])
        return (start, end) if start and end else None
    return None

def quality_check(df: pd.DataFrame, time_column: str = 'Timeline') -> bool:
    """
    Pr√ºft ob:
    - Zeitspalte vorhanden
    - mind. 4 g√ºltige Eintr√§ge (einzelne Zeitpunkte oder Zeitr√§ume)
    - Gesamtzeitraum >= 1 Jahr
    """
    if time_column not in df.columns:
        print(f"‚ùå Zeitspalte '{time_column}' nicht gefunden.")
        return False

    if len(df) < 4:
        print(f"‚ùå Der DataFrame enth√§lt nur {len(df)} Zeilen (mindestens 4 erforderlich).")
        return False

    df = df.copy()
    periods = df[time_column].astype(str).apply(parse_period_string)
    valid_periods = [p for p in periods if p is not None]

    if len(valid_periods) < 4:
        print(f"‚ùå Nur {len(valid_periods)} g√ºltige Zeitangaben erkannt (mindestens 4 erforderlich).")
        return False

    starts, ends = zip(*valid_periods)
    overall_start = min(starts)
    overall_end = max(ends)
    duration = overall_end - overall_start

    if duration < pd.Timedelta(days=365):
        print(f"‚ùå Zeitraum ist zu kurz: nur {duration.days} Tage (mind. 1 Jahr erforderlich).")
        return False

    print(f"‚úÖ Es wurden {len(df)} Berufserfahrungen erkannt. Der Zeitraum erstreckt sich von {overall_start.strftime('%B %Y')} bis {overall_end.strftime('%B %Y')} ({(overall_end - overall_start).days} Tage).")
    print("‚úÖ Qualit√§tspr√ºfung bestanden.")
    return True

def load_resume_data(filepath: str) -> pd.DataFrame:
    
    sep = detect_separator(filepath)

    try:
        # Korrektur: Header ist in Zeile 0
        df = pd.read_csv(filepath, sep=sep, header=0)
    except Exception as e:
        raise ValueError(f"‚ùå Fehler beim Einlesen der CSV: {e}")

    # Leere Spalten entfernen
    df = df.drop(columns=[col for col in df.columns if col.startswith("Unnamed")], errors="ignore")

    # Leere Zeilen entfernen
    df = df.dropna(how="all")

    # Whitespace aus Spaltennamen entfernen
    df.columns = [col.strip() for col in df.columns]

    # ToDo: Hier noch einen Qualit√§tscheck einf√ºgen. z.B. Datensatz nach Relevanz filtern --> vorgeschriebene Spalten oder mit Chatgpt Spaltennamen nach Relevanz auswerten
    quality_check(df) 
    return df

### Einlesen PDF

def normalize_pdf_text(text: str) -> str:
    """
    Bereinigt gestreckten, duplizierten oder zerschossenen Text aus PDF-Scans.
    - Fasst Buchstabenwiederholungen wie 'TTTeeecccchhhh' zu 'Tech' zusammen
    - Entfernt mehrfach wiederholte W√∂rter oder Bl√∂cke
    - Vereinheitlicht Leerzeichen
    """

    # 1. Einzelne Buchstaben-Wiederholungen reduzieren (z.B. SSSoooffftttwwwaaarrreee ‚Üí Software)
    text = re.sub(r'(.)\1{2,}', r'\1', text)

    # 2. √úberlange Wortwiederholungen zusammenfassen
    text = re.sub(r'\b(\w{3,})\s+\1\b', r'\1', text)

    # 3. Whitespace bereinigen
    text = re.sub(r'\s+', ' ', text)

    # 4. Erste Buchstaben wieder gro√ü schreiben (optional)
    text = re.sub(r'(^|\.\s+)([a-z])', lambda m: m.group(1) + m.group(2).upper(), text)

    # 5. Trim
    text = text.strip()

    return text

def extract_clean_text_from_pdf(pdf_path: str) -> str:
    """
    Extrahiert und bereinigt den Text aus einer PDF-Datei mit pdfplumber.
    
    Vorteile gegen√ºber PyPDF2:
    - Bessere Textstruktur
    - Weniger Layout-M√ºll
    - Keine zerrissenen W√∂rter oder Duplikate
    
    R√ºckgabe:
        str: Bereinigter Text der PDF
    """
    try:
        with pdfplumber.open(pdf_path) as pdf:
            raw_text = " ".join(page.extract_text() or "" for page in pdf.pages)
    except Exception as e:
        raise ValueError(f"‚ùå Fehler beim √ñffnen oder Lesen der PDF-Datei: {e}")

    # Text bereinigen
    cleaned_text = normalize_pdf_text(raw_text)

    if not cleaned_text.strip():
        raise ValueError("‚ùå Es konnte kein sinnvoller Text aus der PDF extrahiert werden. M√∂glicherweise enth√§lt die Datei nur Bilder.")
    
    print("‚úÖ Die Stellenauschreibung wurde erkannt.")

    return cleaned_text

