from dotenv import load_dotenv, find_dotenv
# Lade Umgebungsvariablen aus .env
load_dotenv(find_dotenv())

import os
import re
from openai import OpenAI
from prompt_utils import count_tokens, DEFAULT_MODEL

# API-Key aus Umgebungsvariable
api_key = os.getenv("OPENAI_API_KEY")
if not api_key:
    raise ValueError("‚ùå Kein OpenAI API-Key gefunden. Bitte .env pr√ºfen.")

# `client` kann als Alias verwendet werden, falls gew√ºnscht
client = OpenAI(api_key=api_key)


def ask_chatgpt_single_prompt(
    prompt: str,
    model: str = DEFAULT_MODEL,
    temperature: float = 0.2
) -> str:
    """Sendet einen einfachen Prompt an ChatGPT und gibt die Antwort als Text zur√ºck."""
    # Token-L√§nge pr√ºfen
    count_tokens(prompt, model=model)

    # Neue V1-API-Syntax: client.chat.completions.create
    response = client.chat.completions.create(
        model=model,
        temperature=temperature,
        messages=[{"role": "user", "content": prompt}]
    )

    # Extrahiere und returniere den Content
    return response.choices[0].message.content.strip()


def validate_prompt_length(
    prompt: str,
    model: str = DEFAULT_MODEL,
    max_tokens: int = 4096
) -> None:
    """Pr√ºft, ob der Prompt die maximale Token-L√§nge √ºberschreitet."""
    token_count = count_tokens(prompt, model=model)
    if token_count > max_tokens:
        raise ValueError(
            f"Prompt zu lang: {token_count} Tokens, erlaubt sind {max_tokens} Tokens."
        )

def build_prompt(job_text: str, experiences: list[str], model: str = DEFAULT_MODEL, max_tokens: int = 8000) -> str:
    """
    Baut einen Prompt zur Auswahl der 3 relevantesten Erfahrungen und zur R√ºckgabe im HTML-Format.
    """
    intro = (
        "Du bist ein Karrierecoach. Deine Aufgabe ist es, aus den folgenden Berufserfahrungen "
        "die drei relevantesten f√ºr die unten stehende Stellenanzeige auszuw√§hlen.\n\n"
        "Bitte gib die drei Erfahrungen exakt im folgenden HTML-Format zur√ºck:\n\n"
        "<li>\n"
        "  <strong>[Titel der Erfahrung]</strong><br>\n"
        "  <em>[Zeitraum]</em><br>\n"
        "  [Beschreibung in max. 2 S√§tzen]\n"
        "</li>\n\n"
        "‚ö†Ô∏è Gib nur die drei HTML-Elemente zur√ºck ‚Äì ohne Einleitung oder zus√§tzliche Erl√§uterungen."
    )

    job_section = f"\n\nüìå **Stellenanzeige**:\n{job_text.strip()}"
    exp_section = "\n\nüìö **Berufserfahrungen**:\n" + "\n---\n".join(experiences)

    full_prompt = f"{intro}{job_section}{exp_section}"

    validate_prompt_length(full_prompt, model=model, max_tokens=max_tokens)
    return full_prompt

def is_wrapped_with_same_tag(html: str) -> bool:
    """
    Pr√ºft, ob `html` mit <tag>‚Ä¶</tag> umschlossen ist, wobei 'tag' an beiden Stellen identisch sein muss.
    """
    html = html.strip()
    m = re.match(r'^<\s*([A-Za-z0-9]+)(?:\s+[^>]*)?>', html)
    if not m:
        return False
    tag = m.group(1)
    return bool(re.search(rf'</\s*{re.escape(tag)}\s*>$', html))

def validate_html_list(response: str) -> bool:
    """
    Pr√ºft, ob `response` eine HTML-Liste (<ul> oder <ol>) mit genau drei nicht-leeren <li>-Eintr√§gen ist.
    Gibt True zur√ºck, wenn alles passt, sonst False und druckt die gefundenen Fehler.
    """

    # 1) Entferne m√∂gliche Markdown-Codefences
    
    # html ‚Üí Zeilenumbruch
    clean = re.sub(r'html', '\n', response)
    
    # am Zeilenanfang oder -ende beliebig viele ' l√∂schen
    clean = re.sub(r"(\s)*(`)+(\n)*", "", clean)

    # 2) Entferne komplett leere Zeilen oder solche mit nur Whitespace
    #    (?m) aktiviert den Multiline-Mode, sodass ^/$ auf Zeilenanfang/-ende abzielen
    clean = re.sub(r'(?m)^[ \t]*\n', '', clean)

    # 3) √úberpr√ºfe, ob die Liste richtig mit <ul>‚Ä¶</ul> oder <ol>‚Ä¶</ol> umschlossen ist
    if bool(is_wrapped_with_same_tag(clean)) == False:
        print("‚ùå Keine korrekt formatierte HTML-Liste gefunden (fehlende umschlie√üenden <il>/<ul>/<ol>-Tags).")
        print(clean)
        return False

    # 4) Finde alle <li>‚Ä¶</li>
    items = re.findall(r'<li\b[^>]*>(.*?)</li>', clean, flags=re.DOTALL | re.IGNORECASE)
    if len(items) != 3:
        print(f"‚ùå Liste enth√§lt {len(items)} Eintr√§ge, erwartet werden genau 3.")
        return False

    # 5) Pr√ºfe, dass jeder Eintrag nicht nur aus Tags besteht, sondern echten Text enth√§lt
    for idx, inner in enumerate(items, start=1):
        text = re.sub(r'<[^>]+>', '', inner).strip()
        if not text:
            print(f"‚ùå Listeneintrag {idx} ist leer.")
            return False
        
    return clean

def get_response(reduced_text: str, retrieved_docs: str):
    quality_check_rensponse = False
    n = 0
    
    # Prompt bauen und an ChatGPT senden
    while quality_check_rensponse == False and n <= 2:
        
        final_prompt = build_prompt(reduced_text, retrieved_docs)  
        response = ask_chatgpt_single_prompt(final_prompt)
        response = validate_html_list(response)
        n += 1
    
    if response == False:
        print("‚ùå ChatGPT Anfrage nicht wie erwartet.")
        print(response)
    
    return response


